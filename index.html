<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="utf-8">
  <title>Exploring the Uncanny Language of AI Through a New Machine-Made Book</title>

  <!-- This sets the initial view for mobile devices -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://use.typekit.net/zlq4lty.css">
  <link rel="stylesheet" href="https://use.typekit.net/obd5dgj.css">
  
  <style type="text/css" media="screen">
    html {
      /* Make iOS not resize on device rotation */
      -ms-text-size-adjust: 100%; 
      -webkit-text-size-adjust: 100%;

      /* NOTE
      html is set to 62.5% so that all the REM measurements throughout Skeleton
      are based on 10px sizing. So basically 1.5rem = 15px  
      
      Change this if you want to base your REM measuements on something other 
      than 10px as the base
      */
      font-size: 62.5%; 
    }

    body {
      font-size: 1.4em; /* currently ems cause chrome bug misinterpreting rems on body element */
      line-height: 1.7;
      font-weight: 400;
      margin: 0;
      font-family: "halyard-text";
    }

    p {
      margin-top: 1rem;
      font-size:1rem;
    }
      
    p.first {
      margin-top:0;
    }

    h4 {
      margin-top: 0;
      margin-bottom: 0;
      line-height: 1.5; 
      font-family: "halyard-display";

    }

    h4.title {
      padding-top:5rem;
      padding-bottom:10rem;
      font-size: 5rem;
      
    }

    h4.author {
      padding-top: 10rem;
      margin-bottom: 1rem;
      font-size: 2.5rem;
      font-family: halyard-display, sans-serif;
      font-weight: 100;
      font-style: normal;
      
    }

    .wrapper {
      display:flex;
    }

    .column {
      width: 22rem; /* Set your column width here */
      margin: auto; 
    }
    h4.title {
      font-size: 2rem;
      padding-top:2rem;
      padding-bottom: 2.5rem;}
    h4.author {
      font-size: 2.2rem;
    }


    /* Larger than mobile */
    @media (min-width: 400px) {
      .column {
          width: 35rem; /* Set your column width here */
        }
        h4.title {
          font-size: 2rem;
          padding-top:0.1rem;
          padding-bottom: 2.5rem;
        }
        h4.author {
          font-size: 1.7rem;}
      p {
            font-size:1.3rem;
        }
    }

    /* Larger than phablet (also point when grid becomes active) */
    @media (min-width: 550px) {
      .column {
          width: 45rem; /* Set your column width here */
        }
        h4.title {font-size: 2.65rem;}
        h4.author {font-size: 2rem;}
      p {
            font-size:1.7rem;
        }
    }

    /* Larger than tablet */
    @media (min-width: 750px) {
        .column {
          width: 60rem; /* Set your column width here */
        }
        h4.title {font-size: 3.5rem;}
        h4.author {font-size: 2.2rem;}
        p {
            font-size:1.75rem;
        }
    }

    /* Larger than desktop */
    @media (min-width: 1000px) {
      .column {
          width: 80rem; /* Set your column width here */
        }
        h4.title {font-size: 4.3rem;}
        h4.author {font-size: 2.5rem;}
      p {
            font-size:2rem;
        }
    }

    /* Larger than Desktop HD */
    @media (min-width: 1200px) {
      h4.title {font-size: 4.7rem;}
        h4.author {font-size: 3rem;}
      p {
            font-size:2rem;
        }
    }
    
  </style>
</head>
<body>

  <div class="wrapper">
    <div class="column">

        <h4 class="author">Words by Margaret Andersen</h4>
        <h4 class="title">Exploring the Uncanny Language of AI Through a New Machine-Made Book</h4>
      
        <p class="first">Exploring the creative applications of artificial intelligence is hardly a novel idea anymore. Artists and technologists have been collaborating for years on machine learning projects to produce surreal computer visions of the world around us. These idiosyncratic AI recreations of imagery are what singer Clair Evans of electro-pop band YACHT refers to as the computer accent, the visual vernacular that dips into the uncanny valley and signals to viewers that what they’re looking at is definitely not human-made. Or is it? Neural networks can’t initiate concepts or seek out inspiration independently. They canonly iterate on information that’s already been given to them by humans.</p>
        <p>This question of authorship is explored in designer Barney McCann’s new work Book.AI, one of the first artbooks generated by AI and drawn by machine. “I’m always interested in the human side of technology and human’s interaction with it,” McCann says of his design practice and long-running studies in AI. While artists and musicians have embraced AI’s creative potential, he’s actually one of the few designers engaging with this medium.</p>
        <p>At Eye on Design we covered his experimental typeface, Obsolete, a neural network’s shape-shifting translation of sans-serif letterforms, which McCann says is “the closest you can get to a computer’s handwriting.” But with Book.AI he takes things a step further. Not only is the content of the book a product of machine learning, the marks themselves have been made by machine, specifically LetterBot, a literal robot arm that uses an algorithm to copy the writing style of a human hand.</p>
        <p>Each drawing in the book is an AI’s recreation of a diverse range of source imagery, from aerial landscapes to brutalist architecture to Looney Tunes characters. McCann says, “I always start with biological forms first like plant cells or landscapes because it feels like a good way to show the digital world replicating nature.” The results however, are quite a departure from their original subjects.</p>
        <p>Typically neural networks create new things through patterns and repetition. It’s a yes-and-no process of learning, explains McCann. “The only way that the computer knows what’s right and wrong, or makes any decisions really, are from the decisions that are first made by people.” We act as both teachers and curators, training AI systems to identify objects based on the input of thousands of image datasets that have been pre-selected.</p>
        <p>If a neural network looks at 1,000 images of a chair it will begin to create an abstract version of the chair sometimes viewed simultaneously from different angles, perspectives and times, like Duchamp’s Cubist painting Nude Descending a Staircase. Humans continue to improve the accuracy of the AI’s vision by approving their correct identification from their dataset subjects.</p>
        <p>McCann says, “the key difference between my work and something like AI generated portraits of people is that I’m allowing for a lot more machine-made decisions to occur. I’ve given it the initial input, and then it’s extrapolated wildly from there, meaning that I’m not aiming for the recreation of a chair, I’m aiming for its interpretation.”</p>
        <p>Sometimes he’ll cross-pollinate data by using two different inputs like the mitochondria of a cell paired with paintings by Matisse to create a series of sinuous and organic shapes that hint at the subjects’ original forms but are transformed into something entirely new and unexpected. By coupling an AI brain with the LetterBot arm, the machine not only functions as the creative source of the artwork but also physically as the artist as well. “That to me is really the mind blowing part,” he says. “Not only is the AI coming up with the idea, but it’s also executing the idea on its own. This book could be made by itself. All I did was fold the pages.”</p>
        <p>But that’s not entirely true. While it’s difficult to measure how much of the human element exists in the final output from a robot artist, it’s still a creative partnership between human and machine, with the source of inspiration originating in humans and the datasets they’ve selected. For McCann, Book.AI is a collaboration with machines, and an exploration of alternative relationships with technology. His particular research interests are AI’s impact on our society and the practical implications of it; and the numerous times that AI systems have created racist, sexist, and discriminatory situations through algorithmic bias.</p>
        <p>For people outside of AI research it’s difficult to visualize how these systems function and how AI is already influencing our lives in both invisible and very noticeable, sometimes harmful ways, particularly to those in marginalized communities. “The role of art and media is to make something more understandable and accessible,” McCann says, “pieces like Book.AI takes these abstract concepts and makes them feel less unquestionable and unmanageable. That’s one of the reasons why I’m so drawn to AI.”</p>
        
        
    </div>
  </div>


</body>
</html>